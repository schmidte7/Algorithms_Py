{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canada -> switzerland 0.456184364102078\n",
      "disaster -> conflict 0.544502968506453\n",
      "flood -> disaster 0.4050564499452524\n",
      "car -> industry 0.45431914933483547\n",
      "road -> rail 0.800202306662735\n",
      "train -> road 0.49526152550920777\n",
      "rail -> road 0.800202306662735\n",
      "germany -> switzerland 0.5314314472679995\n",
      "switzerland -> germany 0.5314314472679995\n",
      "technology -> industry 0.587759045516596\n",
      "industry -> conflict 0.6028670935055592\n",
      "conflict -> industry 0.6028670935055592\n"
     ]
    }
   ],
   "source": [
    "import pprint #  Provides a capability to “pretty-print” arbitrary Python data structures in a vertical form\n",
    "import re # Import re for the splitting of words based on punctuation or spacing\n",
    "import math # Gives access to the underlying C library functions - math.sqrt()\n",
    "\n",
    "def read_reference_text(filename: str) -> list[list[str]]: # Call in a function that reads in the text reference file\n",
    "    \"\"\"\n",
    "        The first function imports a reference text file that has 100,000 lines. Those lines get individually called into\n",
    "        a list of sentences within a list that has strings within that inner list. Throughout the function, there are steps\n",
    "        to remove, replace, and lower the strings (words) of each line.\n",
    "        - Resource: Project PDF\n",
    "\n",
    "        Pre-condition:\n",
    "        - filename points to the correct location\n",
    "        - filename contains lines ith content (sentences)\n",
    "        Post-condition:\n",
    "        - text file is a list of sentences that is broken into a list of words that follows the criteria\n",
    "        within the code (ex. lowercase, split, etc.)\n",
    "\n",
    "        Argument:\n",
    "        -  filename(str): A string that references the location of the text file.\n",
    "\n",
    "        Returns:\n",
    "        - list[list[str]] - \"text\": A list of a list of lines that contains strings (words). The words that are appended to the\n",
    "        text list are those that are lowercased, '\\n', and quotes replaced, and does not include any punctuation.\n",
    "    \"\"\"\n",
    "    f = open(filename, mode = 'r', encoding=\"utf8\")  # Reads ('r') in the text file. Using \"utf8\" file encoding\n",
    "\n",
    "    text = [] # Creates an empty list for the output of the read_reference_text() function\n",
    "\n",
    "    for sentences in f: # Iterates through the lines of sentences within f (text reference file)\n",
    "        sentences = sentences.lower() # For each word, this operation will lowercase each letter\n",
    "        sentences = sentences.replace('\\n', ' ') # Replaces the new line character with a space\n",
    "        sentences = sentences.replace('\"', ' ') # Replace the quotes with a space\n",
    "        words = re.split(\"[ ,;.)'/(!+?:-]\", sentences) # Splits the sentences based on the different punctuation marks\n",
    "        text.append(words) # Appends words within the sentence within a list to create a list of a list of strings\n",
    "    return text # Returns the text that was originally an empty list\n",
    "    f.close() # Closed the opened reference text file\n",
    "\n",
    "text = read_reference_text(\"ref-sentences.txt\")\n",
    "\n",
    "def make_word_vector(w: str, text: list[list[str]]) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "         This function iterates over each sentence to check if the word appears in that line and returns a dictionary\n",
    "         with contains the word_list (key) and those words in the sentences and how often they appear (value)\n",
    "        - Resource: Project PDF\n",
    "\n",
    "        Pre-condition:\n",
    "        - text should already be formatted as list[list[str]]\n",
    "        - w should be included in a word_list (for the example, I just used \"Spain\")\n",
    "\n",
    "        Post-condition:\n",
    "        - Vector contains all words that are in a sentence that contains the w in a {str, int} format\n",
    "\n",
    "        Arguments:\n",
    "        - w(str): The word that the dictionary is created for\n",
    "        - text(list[list[str]]): A list of a list of lines that contains strings (words) that pertain to the w\n",
    "\n",
    "        Returns:\n",
    "        - dict[str, int] - \"vector\": Contains the word w and the amount of times that another word that is not the same\n",
    "        as w appears in the same line. The int will then count how many times it appears\n",
    "    \"\"\"\n",
    "\n",
    "    # Given stopwords list (Project PDF)\n",
    "    stopwords = set(\n",
    "        [\"s\", \"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\",\n",
    "         \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\",\n",
    "         \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"around\", \"as\",\n",
    "         \"at\", \"back\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\",\n",
    "         \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\", \"but\", \"by\",\n",
    "         \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\",\n",
    "         \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\",\n",
    "         \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\",\n",
    "         \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\",\n",
    "         \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\",\n",
    "         \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\",\n",
    "         \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\",\n",
    "         \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\",\n",
    "         \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\",\n",
    "         \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\",\n",
    "         \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\",\n",
    "         \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\", \"please\", \"put\",\n",
    "         \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\",\n",
    "         \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\",\n",
    "         \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\",\n",
    "         \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\",\n",
    "         \"these\", \"they\", \"thick\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\",\n",
    "         \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\",\n",
    "         \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\",\n",
    "         \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\",\n",
    "         \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\",\n",
    "         \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"])\n",
    "\n",
    "    vector_list = []  # Creates an empty list called vector_list\n",
    "    for sentence in text: # Iterates through each sentence in the text list\n",
    "            for word in sentence: # Iterates through each word in the sentence\n",
    "                if w in sentence: # Looks if w (word_list provided) is in that individual sentence\n",
    "                    vector_list.append(word) # Appends the word to the vector_list\n",
    "\n",
    "    vector = {}  # Creates an empty dictionary called vector\n",
    "    for word in vector_list: # Iterate through each word in the vector_list\n",
    "        if len(word) >= 3 and word not in stopwords and word !=w: # Does not include words less than three characters, stopwords, or if the word is in the w (ex. \"Spain\")\n",
    "            if word in vector: # If the word is in the empty dictionary called 'vector'\n",
    "                vector[word] = vector[word] + 1 # Add 1 to the value if the key already exists\n",
    "            else:\n",
    "                vector[word] = 1 # If the value/key do not exist, add it to the dictionary and add one to the value\n",
    "\n",
    "    return vector # Returns the dictionary called vector\n",
    "\n",
    "# Ran tests for dict1 and dict2 to compare with \"Spain\"\n",
    "# dict1= make_word_vector('industry',text)\n",
    "# dict2= make_word_vector('conflict',text)\n",
    "\n",
    "def sim_word_vec(dict1: dict[str, int], dict2: dict[str, int]) -> float:\n",
    "    \"\"\"\n",
    "        The function computes the scalar product of two dictionaries\n",
    "        and then computes the cosine similarity of the texts\n",
    "        - Resource: Sets and Dictionaries (slides 19 to 22)\n",
    "\n",
    "        Pre-condition:\n",
    "        - String has to be more than 2 characters and not a stopword\n",
    "        - Integer >= 0\n",
    "        Post-condition:\n",
    "        - Returns a cosine_sim > 0\n",
    "        - Returns a float value for cosine_sim\n",
    "\n",
    "        Arguments:\n",
    "        -  dict1(dict[str,int]): Dictionary that contains one string and the words that appear with that main string with how often it appears\n",
    "        -  dict2(dict[str,int]): Dictionary that contains one string and the words that appear with that main string with how often it appears\n",
    "\n",
    "        Returns:\n",
    "        - float - \"cosine_sim\": The scalar product of dict1 and dict2\n",
    "    \"\"\"\n",
    "\n",
    "    sp12 = 0.0 # Scalar product of both (1 and 2) dictionaries\n",
    "    sp_1 = 0.0 # Scalar product of the first (1) dictionary\n",
    "    sp_2 = 0.0 # Scalar product of the second (2) dictionary\n",
    "    for word in dict1:\n",
    "        sp12 += dict1[word] * dict2.get(word, 0)  # Word not in dict2 → 0\n",
    "        sp_1 += dict1[word] * dict1.get(word,0) # Word not in dict1 → 0\n",
    "    for word in dict2:\n",
    "        sp_2 += dict2[word] * dict2.get(word,0) # Word not in dict2 → 0\n",
    "        cosine_sim = sp12 / (math.sqrt(sp_1 * sp_2)) # Compute cosine similarity\n",
    "    return cosine_sim\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "            The function compares all the word combinations for the test_words and prints the maximum values for each word and their highest similarity.\n",
    "\n",
    "            Pre-condition:\n",
    "            - Test of words is included (all lower cased)\n",
    "            Post-condition:\n",
    "            - The outcome only contains the number of words that are in the list of test words (example: 12 lines)\n",
    "\n",
    "            Returns:\n",
    "            - list - \"sim_comparison\": Contains the word_test1 and word_test2 words and their cosine similarity value\n",
    "        \"\"\"\n",
    "    #filename = 'ref-sentences.txt'\n",
    "    #print(read_reference_text(filename))\n",
    "    #w = \"spain\"\n",
    "\n",
    "    # word_list1 includes two fish strings\n",
    "    word_list1 = [\"spain\", \"anchovy\", \"france\", \"internet\", \"china\", \"mexico\", \"fish\", \"industry\", \"agriculture\",\n",
    "                 \"fishery\", \"tuna\", \"transport\", \"italy\", \"web\", \"communication\", \"labour\",\"fish\", \"cod\"]\n",
    "    # word_list2 includes one fish string\n",
    "    word_list2 = [\"spain\", \"anchovy\", \"france\", \"internet\", \"china\", \"mexico\", \"fish\", \"industry\", \"agriculture\",\n",
    "                 \"fishery\", \"tuna\", \"transport\", \"italy\", \"web\", \"communication\", \"labour\", \"cod\"]\n",
    "    # Contains the list of test words that are to be compared\n",
    "    words_test = [\"canada\", \"disaster\", \"flood\", \"car\", \"road\", \"train\", \"rail\", \"germany\", \"switzerland\", \"technology\", \"industry\", \"conflict\"]\n",
    "\n",
    "    # Creates dictionaries for every word that is in the word_test\n",
    "    word_dict = {word:make_word_vector(word, text) for word in words_test}\n",
    "    #print(word_dict)\n",
    "\n",
    "    sim_comparison = [] # Creates an empty list called sim_comparison\n",
    "    for i in range(len(words_test)): # Iterates over the 12 words in word_test\n",
    "        max_sim = 0 # Create a max value at 0 to compare to sim_word_vec value\n",
    "        for j in range(len(words_test)): # An inner loop to iterate over the 12 words in word_test\n",
    "            if j == i: # If the two words equal one another, do not include in output\n",
    "                pass\n",
    "            else:\n",
    "                sim = sim_word_vec(word_dict[words_test[i]], word_dict[words_test[j]]) # sim to compare to max_sim to override if it is the largest value\n",
    "                if sim > max_sim: # If sim is greater than max_sim\n",
    "                    max_sim = sim # Replace what the previous value was before with the new sim\n",
    "                    j_position = j # Equal j_position to wherever j has iterated through\n",
    "        print(words_test[i], \"->\",words_test[j_position], max_sim) # Prints the output of the maximum value between the two dictionary words\n",
    "\n",
    "   # print(sim_word_vec(dict1, dict2))\n",
    "    #pprint.pprint(sim_comparison)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
